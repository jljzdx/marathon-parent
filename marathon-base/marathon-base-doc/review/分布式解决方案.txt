分布式事务
|-base理论
  |--【必须保证原子性和持久性，然后降低一致性和隔离性的要求】
  |--基本可用、柔性状态、最终一致性
|-CAP定理
  |--一致性、可用性、分区容错性
|-柔性事务解决方案
  |--两阶段型（2PC）
  |--补偿型（TCC）
  |--异步确保型【可靠消息一致性】
  |--最大努力型【如：支付回调】
|-可靠消息最终一致性
  |--消息中间件的应用场景
    |---异步缓存
    |---解耦
    |---并发缓冲【一次消费不了太多线程，先缓冲下来，再慢慢消费掉】
  |--消息中间件重复发送不可避免，所以要约束
    |---指定重复发送的约束条件【消费者的业务处理要求幂等性】
	|---限制重发次数，超过次数让其进入死亡队列中
	|---只有进行ACK确认，并且更新消息投递状态的消息才不会再重发了

TX-LCN:原理
|-创建事务组、添加事务组、关闭事务组
|-底层使用3PC
|-在调用A.a1()前，先请求TM创建一个事务组，当A.a1()通过RPC调用B.b1()时，会把groupId传递过来，等到B.b1()执行完毕，再请求添加事务组，并且做了一个叫做假关闭的操作，不让事务提交，接下来A.a1()异常了，这时候，会通知TM，TM会通过Netty通知B进行事务回滚
|-补偿机制：
  |--通常发生在关闭事务组时，由于在通知相应模块提交事务时，通知不到（可能由于模块挂了或网络问题），
     这时会通知发起方把该次事务识别为待补偿，发起方再异步通知TxManager，TxManager把这次事务组信息存储到redis，
     然后调用补偿回调接口（比如发短信、邮箱）通知，补偿的时候，相当于重新让发起方再执行一遍流程，
     只不过除了刚才没通知成功的模块要提交，其他都要回滚

RabbitMQ解决分布式事务：
1、使用Confirm确认机制，保证生产者消息发送成功；
2、使用ACK模式+补偿机制（注意幂等），保证消费者成功消费消息；
3、使用补单机制，确保第一个事务执行成功

redis分布式锁：
获取锁：
private static final String LOCK_SUCCESS = "OK";
String result = jedis.set(lockKey, value, “NX”, “PX”, expireTime);
        if (LOCK_SUCCESS.equals(result)) {
            return true;
        }
        return false;
不要使用：
Long result = jedis.setnx(lockKey, requestId);
if (result == 1) {
        // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁
        jedis.expire(lockKey, expireTime);
    }
解锁：
private static final Long RELEASE_SUCCESS = 1L;
String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
        Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId));

        if (RELEASE_SUCCESS.equals(result)) {
            return true;
        }
        return false;
不要使用：
// 判断加锁与解锁是不是同一个客户端
    if (requestId.equals(jedis.get(lockKey))) {
        // 若在此时，这把锁突然不是这个客户端的，则会误解锁
        //比如客户端A加锁，一段时间之后客户端A解锁，在执行jedis.del()之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端A再执行del()方法，则将客户端B的锁给解除了。
        jedis.del(lockKey);
    }
实现Redis分布式锁的最简单的方法就是在Redis中创建一个key，value必须是唯一的，为了保证正确的释放锁，这个key有一个失效时间（TTL)，以保证锁最终会被自动释放掉（这个对应特性2）。当客户端释放资源(解锁）的时候，会删除掉这个key。
如果Redis挂了怎么办？你可能会说，可以通过增加一个slave节点解决这个问题。但这通常是行不通的。如下：
1、客户端A从master获取到锁
2、在master将锁同步到slave之前，master宕掉了。
3、slave节点被晋级为master节点
4、客户端B取得了同一个资源被客户端A已经获取到的另外一个锁。安全失效！
为什么value必须唯一，举个例子：
客户端A取得资源锁，但是紧接着被一个其他操作阻塞了，当客户端A运行完毕其他操作后要释放锁时，原来的锁早已超时并且被Redis自动释放，并且在这期间资源锁又被客户端B再次获取到。如果仅使用DEL命令将key删除，那么这种情况就会把客户端B的锁给删除掉。
Redlock算法：
我们假设有5个Redis master节点，这是一个比较合理的设置
1、获取当前Unix时间，以毫秒为单位。
2、依次尝试从N个实例，使用相同的key和随机值获取锁。在步骤2，当向Redis设置锁时,客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个Redis实例。
3、客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。
4、如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。
5、如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功）。


限流：
|-几个主要概念
  |--服务降级：在高并发情况下，为了防止用户一直等待，直接给用户返回一个友好的提示
  |--服务熔断：熔断机制是为了保护服务，在高并发情况下，如果流量超出设定的阈值，直接拒绝访问服务接口，然后和服务降级一起使用的
     |---如果当前健康状况（请求失败数/请求总数）高于设定阈值（默认为10秒内的20次故障），开关保持关闭，反之，开关打开，请求被禁止通过，进入降级操作，经过一段时间后，
         断路器会进入半开状态，这是只允许一个请求通过，如果该请求成功，则断路器保持关闭状态，反之，打开状态
  |--雪崩效应：由于默认情况下，只有一个线程池维护所有的服务接口，如果流量达到tomcat线程池默认的极限，可能导致服务无法访问
  |--服务隔离：保证每个服务接口互不影响。用来解决雪崩的，有两种方式【线程池、信号量】
  |--雪崩效应解决：
     |---通过Hiytrix的服务降级【为了用户体验，fallback使用异步线程callable和future返回结果】
	 |---服务熔断机制【为了保护服务，如果流量超出设置的默认的阈值10，自动开启保护服务功能，和降级一起使用】
	 |---服务隔离【线程池隔离：使用@HystrixCommand会另外开启一个线程池】，注意走降级超时时间，默认是1秒
|-滑动窗口计数器：假如限制每60秒只能接受10请求，超过就降级，为了防止在临界点同时出现20个请求。
|-令牌桶算法【RateLimiter是guava提供的】：开启一个线程固定速率往桶中存令牌，客户端请求时向桶中取令牌，桶是有固定容量的

Oauth2.0协议
|-生成授权链接，获取授权码code
|-根据授权码获取令牌AccessToken
|-根据令牌获取openId
|-使用openId获取用户信息

Feign：
|-关闭重试机制，避免接口没有做幂等性，OkToRetryOnAllOperations=false
|-合理设置ReadTimeout、ConnectTimeout，建议ReadTimeout可以稍微设大点
|-底层也是使用动态代理
|-原理
  |--首先通过@EnableFeignCleints注解开启FeignCleint
  |--根据Feign的规则实现接口，并加@FeignCleint注解
  |--程序启动后，会进行包扫描，扫描所有的@ FeignCleint的注解的类，并将这些信息注入到ioc容器中。
  |--当接口的方法被调用，通过jdk的代理，来生成具体的RequesTemplate
  |--RequesTemplate在生成Request
  |--Request交给Client去处理，其中Client可以是HttpUrlConnection、HttpClient也可以是Okhttp
     |---如果想使用HttpClient，只需要
     feign.httpclient.enabled=true
     <dependency>
         <groupId>com.netflix.feign</groupId>
         <artifactId>feign-httpclient</artifactId>
         <version>RELEASE</version>
     </dependency>
     |---如果想使用Okhttp，只需要
     feign.okhttp.enabled=true
     <dependency>
         <groupId>com.netflix.feign</groupId>
         <artifactId>feign-okhttp</artifactId>
         <version>RELEASE</version>
     </dependency>
  |--最后Client被封装到LoadBalanceClient类，这个类结合类Ribbon做到了负载均衡。
微服务拆分原则：
1. 单一职责、高内聚低耦合

2. 服务粒度适中

3. 考虑团队结构

4. 以业务模型切入

5. 演进式拆分

6. 避免环形依赖与双向依赖



单点登陆：
传统解决方案：将用户信息写到session中，存储到cookie中，但系统A和系统B的域名必须一样。当域名不一样的时候，就需要使用CAS。
TGC[Ticket-granting cookie]：CAS 会将生成的 TGT 放在 session 中，而 TGC 就是这个 session 的唯一标识(sessionId)，可以认为是 TGT 的key，TGC 以 cookie 的形式保存在浏览器中，每个请求都会尝试携带 TGC
TGT[Ticket Granting ticket]：是用于验证用户登录成功的唯一方式，也可以理解为用户信息，CAS 通过 Cookie 值（TGC）为 key 查询缓存中有无 TGT（TGC:TGT（key:value）），如果有的话就说明用户已经登录成。
ST[Service ticket]：由TGT生成的一次性票据，用于验证，只能用一次。相当于Server发给Client一张票，然后Client拿着这个票再来找Server验证，看看是不是Server签发的。

























