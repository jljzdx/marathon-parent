redis:
|-redis应用场景：缓存常用数据、高并发读写、计数器（订单号每天从1开始）分布式全局ID、防止前端重复提交、分布式锁
|-Redis事务：命令格式错误，则回滚；命令格式正确，单命令操作的数据类型错误，则不回滚
|-watch：在multi命令之前，监听某个键值对（K-V），在执行exec命令的时候，如果K-V发生变化，则回滚，反之，执行事务队列中的命令
redis集群
|-基本类型和命令
  |--Strings、lists、hashes、sets、sorted sets
  |--auth wangwb123
  |--flushdb【清理当前库的缓存数据】、flushall【清理所有库的缓存数据】
|-Redis持久化技术
  |--AOF日志持久化【实时】效率低，靠谱
    |---【appendfsync always/everysec/no:同步频率】【no-appendfsync-on-rewrite yes:正在导出rdb快照的过程中，要不要停止同步aof】
    |---AOF重写：把内存中的数据，逆化成命令，写到aof日志中，以解决aof日志过大问题。反复操作同一个key会使得aof文件庞大，所以就使用【auto-aof-rewrite-percentage 100：增长率100%时，重写】【auto-aof-rewrite-min-size 64M：至少超过64M开始重写】
	|---使用【./bin/redis-benchmark -n 20000】执行20000个命令
  |--RDB快照持久化【非实时】效率高，不靠谱，如果断电会丢失数据
  |--官方推荐rdb和aof配合使用,恢复速度rdb比aof快，如果两个文件都存在的话，将使用aof进行恢复
|-常见集群方案
  |--分片技术（mycat），需要故障转移功能
  |--主从复制，缺点：数据冗余，非常浪费内存
  |--redis强烈推荐：redis-cluster【内部使用AOF】
|-redis-cluster
  |--官方建议最好搭6台集群
  |--卡槽：0-16384，卡槽会均摊给各个节点，当要set name wang时，根据key使用CRC16算法得到一个数字，然后%16384
  |--节点重定向，例如：set name wang通过CRC16算法取余最终存储在9001，此时如果你是在9002进行集群操作的，会自动重定向到9001，查询也是一样
  |--客户端链接：redis-cli -c -h 127.0.0.1 -p 9001
  |--集群步骤
    |--关闭防火墙
	|--安装纯净版本的redis：
	  |---tar -zxvf redis-3.2.9.tar.gz
	  |---cd redis-3.2.9
	  |---make
	  |---cd src
	  |---make install prefix=/usr/local/redis

ElasticSearch:
|-第一个命令
GET /_count
{
    "query": {
        "match_all": {}
    }
}
|-索引
索引（名词）：
如前所述，一个 索引 类似于传统关系数据库中的一个 数据库 ，是一个存储关系型文档的地方。 索引 (index) 的复数词为 indices 或 indexes 。
索引（动词）：
索引一个文档 就是存储一个文档到一个 索引 （名词）中以便它可以被检索和查询到。这非常类似于 SQL 语句中的 INSERT 关键词，除了文档已存在时新文档会替换旧文档情况之外。
倒排索引：
关系型数据库通过增加一个 索引 比如一个 B树（B-tree）索引 到指定的列上，以便提升数据检索速度。Elasticsearch 和 Lucene 使用了一个叫做 倒排索引 的结构来达到相同的目的。
|-索引文档
PUT /megacorp/employee/1
{
    "first_name" : "John",
    "last_name" :  "Smith",
    "age" :        25,
    "about" :      "I love to go rock climbing",
    "interests": [ "sports", "music" ]
}
解释【三个必须的元数据元素】：
megacorp：索引名称【_index】
employee：类型名称【_type】
1：特定雇员的ID【_id】
|-检索文档
GET /megacorp/employee/1
GET /megacorp/employee/_search

全文搜索："_score"：相关性得分，匹配程度
GET /megacorp/employee/_search
{
    "query" : {
        "match" : {
            "last_name" : "Smith"
        }
    }
}

GET /megacorp/employee/_search
{
    "query" : {
        "bool": {
            "must": {
                "match" : {
                    "last_name" : "smith"
                }
            },
            "filter": {
                "range" : {
                    "age" : { "gt" : 30 }
                }
            }
        }
    }
}
短语搜索：
GET /megacorp/employee/_search
{
    "query" : {
        "match_phrase" : {
            "about" : "rock climbing"
        }
    }
}
高亮搜索：
GET /megacorp/employee/_search
{
    "query" : {
        "match_phrase" : {
            "about" : "rock climbing"
        }
    },
    "highlight": {
        "fields" : {
            "about" : {}
        }
    }
}
聚合分析 ：
GET /megacorp/employee/_search
{
  "aggs": {
    "all_interests": {
      "terms": { "field": "interests" }
    }
  }
}
GET /megacorp/employee/_search
{
  "query": {
    "match": {
      "last_name": "smith"
    }
  },
  "aggs": {
    "all_interests": {
      "terms": {
        "field": "interests"
      }
    }
  }
}
GET /megacorp/employee/_search
{
    "aggs" : {
        "all_interests" : {
            "terms" : { "field" : "interests" },
            "aggs" : {
                "avg_age" : {
                    "avg" : { "field" : "age" }
                }
            }
        }
    }
}
|-集群健康
GET /_cluster/health
|-添加索引
PUT /blogs
{
   "settings" : {
      "number_of_shards" : 3,
      "number_of_replicas" : 1
   }
}
|-文档
查看文档是否存在：HEAD /megacorp/employee/1
更新文档：
PUT /website/blog/123
{
  "title": "My first blog entry",
  "text":  "I am starting to get the hang of this...",
  "date":  "2014/01/02"
}
创建文档：PUT /website/blog/123/_create
删除文档：DELETE /website/blog/123
|-索引设置
PUT /my_temp_index
{
    "settings": {
        "number_of_shards" :   1,
        "number_of_replicas" : 0
    }
}

Elasticsearch中默认的标准分词器，这个分词器在处理中文的时候会把中文单词切分成一个一个的汉字，因此引入es之中文的分词器插件es-ik就能解决这个问题

zookeeper【树状存储结构】
|-应用场景
  |--1.注册中心   2.分布式配置中心   3.负载均衡   4.分布式锁  5.发布订阅
|-四种类型的znode
  |--持久化目录节点、持久化顺序编号目录节点、临时目录节点、临时顺序编号目录节点

RabbitMQ:
|-RabbitMQ安装路径：cd /usr/local/Cellar/rabbitmq/3.8.0
|-启动：rabbitmq-server -detached
|-查看状态：rabbitmqctl status
|-关闭：rabbitmqctl stop
|-可视化监控界面：http://localhost:15672【guest/guest】
|-如何确保消息100%发送至RabbitMQ?
1、发送消息到MQ前，先将消息持久化
2、在confirm模式，当消息发送成功，将消息状态更新为投递成功
3、使用定时任务（每30秒查一下投递失败的数据），将投递失败的消息，重新投递（最大重新投递次数3）
使用confirm模式（异步的），当消息发送成功，信道会发送一个确认给生产者；如果发送失败，信道会发送nack（未确认）消息给生产者
|-如何确保消费者消费了消息？
使用ACK手动确认机制
|-如何避免消息重复投递或重复消费？
使用全局MessageId
Message message = MessageBuilder.withBody(msg.getBytes()).setContentType(MessageProperties.CONTENT_TYPE_JSON)
.setContentEncoding("UTF-8").setMessageId(UUID或订单号).build();
|-如何确保消息不丢失？
持久化
|-RabbitMQ有什么好处？
异步、解耦、流量削峰
|-死信队列条件
消息被拒绝 (basic.reject or basic.nack) 且带 requeue=false不重新入队参数或达到的retry重新入队的上限次数
消息的TTL(Time To Live)-存活时间已经过期
队列长度限制被超越（队列满，queue的"x-max-length"参数）


Tomcat调优：
|-内存:JAVA_OPTS="-Xms 1G -Xmx 1G"
|-线程：<Connector port="80" protocol="HTTP/1.1" maxThreads="600" minSpareThreads="100" maxSpareThreads="500" acceptCount="700"
     connectionTimeout="20000"  />
|-压缩：<Connector port="8080" protocol="HTTP/1.1"
     connectionTimeout="20000"
     redirectPort="8181" compression="500"
     compressableMimeType="text/html,text/xml,text/plain,application/octet-stream" />
|-IO：使用Apache可移植运行时（Apache Portable Runtime简称APR）
<Connector port="8080" protocol="org.apache.coyote.http11.Http11AprProtocol"
               connectionTimeout="20000"
               redirectPort="8443" />
tomcat中一共有三种运行模式，分别是:bio,nio,apr:
bio是阻塞式IO操作，使用的是传统的java i/o处理方式，对于每一个请求都要创建一个线程来进行处理，所以开销较大不适合处理高并发的场景
nio是基于java中非阻塞IO操作的API实现，比传统的i/o处理方式有更高的并发运行性能
apr是从操作系统级别解决异步IO问题，大幅度提高服务器的并发处理性能，也是Tomcat生产环境运行的首选方式,apr的本质就是使用jni技术调用操作系统底层的IO接口

maven继承和聚合：
聚合：为了能够使用一条命令就构建多个模块
继承：在构建多个模块的时候，往往会多有模块有相同的依赖
依赖冲突：
1：如果依赖路径的长度不同，则“短路优先”：
A—>B—>C—>D—>E—>X(version 0.0.1)
A—>F—>X(version 0.0.2)
2：依赖路径长度相同情况下，则“先声明优先”：
A—>E—>X(version 0.0.1)
A—>F—>X(version 0.0.2)
