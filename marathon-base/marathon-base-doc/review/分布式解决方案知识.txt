1、分布式锁：
背景：有些的时候，我们必须保证系统里的某一个方法在同一时间内只能被同一个线程执行。在单机环境，使用JDK API解决；在分布式环境，使用分布式锁。
三种实现方式：RedisLockRegistry、Redission、自己实现
两个应用场景：
|-微信端access_token刷新（分布式锁可以保证access_token只刷新一次，刷新完成之后放入缓存，其他请求直接从缓存读取）；
|-分布式部署的定时任务（分布式锁可以保证同一时刻只有一个节点的定时任务执行）
|-防止页面重复提交：String token = request.getHeader("Authorization");String path = request.getServletPath();String key = token + path;

获取锁：
private static final String LOCK_SUCCESS = "OK";
String result = jedis.set(lockKey, value, “NX”, “PX”, expireTime);
if (LOCK_SUCCESS.equals(result)) {
    return true;
}
return false;
不要使用：
Long result = jedis.setnx(lockKey, requestId);
if (result == 1) {
    // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁
    jedis.expire(lockKey, expireTime);
}
解锁：
private static final Long RELEASE_SUCCESS = 1L;
String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId));

if (RELEASE_SUCCESS.equals(result)) {
    return true;
}
return false;
不要使用：
// 判断加锁与解锁是不是同一个客户端
if (requestId.equals(jedis.get(lockKey))) {
    // 若在此时，这把锁突然不是这个客户端的，则会误解锁
    //比如客户端A加锁，一段时间之后客户端A解锁，在执行jedis.del()之前锁突然过期了（这种就是所谓的代码块执行时间超过设置的过期时间），
    //此时客户端B尝试加锁成功，然后客户端A再执行del()方法，则将客户端B的锁给解除了。
    jedis.del(lockKey);
}
还存在一个问题：
|-如果代码块执行时间超过设置的过期时间，锁会自动释放，这时就会存在两个节点都在执行代码块，显然不合理
|-解决办法：可以开启一个守护线程，用来给快要过期的锁“续航”
实现Redis分布式锁的最简单的方法就是在Redis中创建一个key，value必须是唯一的，为了保证正确的释放锁，这个key有一个失效时间（TTL)，
以保证锁最终会被自动释放掉（这个对应特性2）。当客户端释放资源(解锁）的时候，会删除掉这个key。
如果Redis挂了怎么办？你可能会说，可以通过增加一个slave节点解决这个问题。但这通常是行不通的。如下：
1、客户端A从master获取到锁
2、在master将锁同步到slave之前，master宕掉了。
3、slave节点被晋级为master节点
4、客户端B取得了同一个资源被客户端A已经获取到的另外一个锁。安全失效！
为什么value必须唯一，举个例子：
客户端A取得资源锁，但是紧接着被一个其他操作阻塞了，当客户端A运行完毕其他操作后要释放锁时，原来的锁早已超时并且被Redis自动释放，
并且在这期间资源锁又被客户端B再次获取到。如果仅使用DEL命令将key删除，那么这种情况就会把客户端B的锁给删除掉。
Redlock算法：
我们假设有5个Redis master节点，这是一个比较合理的设置
    1、获取当前Unix时间，以毫秒为单位。
    2、依次尝试从N个实例，使用相同的key和随机值获取锁。在步骤2，当向Redis设置锁时,客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个Redis实例。
    3、客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。
    4、如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。
    5、如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功）。

2、分布式事务解决方案
|-base理论
  |--BASE是对CAP中一致性和可用性权衡的结果
  |--基本可用、软状态、最终一致性
|-CAP定理
  |--一致性、可用性、分区容错性（必要的）
|-柔性事务解决方案
  |--基于XA协议的两阶段型（协调者和参与者；准备和提交；存在诸多问题：单点故障问题、阻塞（等待参与者回复）、数据不一致（提交时只通知到部分参与者））
  |--三阶段型（引入超时机制，解决阻塞问题，但也因此可能导致数据不一致问题；引入了预备阶段，提早发现无法执行的参与者，并终止事务）
  |--TCC事务补偿型（Try、Confirm、Cancel，存在诸多问题：复杂场景下是不推荐使用的、代码量庞大，耦合性高），可以使用tcc-transaction框架
  |--异步确保型【可靠消息最终一致性，正反向消息机制+定时任务实现】
  |--阿里GTS（收费）
  |--阿里Seata，但不够成熟
|-开源项目的分布式事务实现
  |--RocketMQ
  |--Saga

RabbitMQ解决分布式事务（最终一致性思想）：
1、使用Confirm确认机制，保证生产者消息发送成功；
2、使用ACK模式+补偿机制（注意幂等），保证消费者成功消费消息；
3、使用补单机制，确保第一个事务执行成功，因为可能队列执行成功后，后面的代码报异常，导致添加订单事务回滚（多创建一个补单的消费者，判断订单是否创建成功）


3、分布式单点登陆：
|-登录流程：
  |--用户访问系统1的受保护资源，发现用户未登录，重定向到sso认证中心，并将请求地址做为参数
  |--sso认证发现用户未登录，引导去登录页面
  |--用户输入正确的用户名、密码登录后，sso认证中心创建全局会话和授权令牌
  |--sso认证中心携带授权令牌跳转到原请求地址（系统1）
  |--系统1拿到授权令牌去sso认证中心校验成功，把系统1记录下来，后续注销使用
  |--系统1使用授权令牌创建局部会话，返回受保护资源
  |--用户访问系统2的受保护资源，发现用户未登录，重定向到sso认证中心，并将请求地址做为参数
  |--sso认证中心发现用户已登录，就携带授权令牌跳转到原请求地址（系统2）
  |--系统2拿到授权令牌去sso认证中心校验成功，把系统1记录下来，后续注销使用
  |--系统1使用授权令牌创建局部会话，返回受保护资源
|-注销
  |--用户向系统1发起注销请求
  |--系统1拿着授权令牌去sso认证中心发起注销请求
  |--sso认证中心检验授权令牌有效，销毁全局会话，取出所有用此令牌注册的系统地址
  |--sso认证中心向所有注册系统发起注销请求
  |--各注册系统接收sso认证中心的注销请求，销毁局部会话
  |--sso认证中心引导用户至登录页面


1、热点隔离
业务隔离：卖家申请参与秒杀的商品，当真正开始时我们可以提前做好预热
系统隔离：申请单独的域名，目的也是让请求落到不同的集群中
数据隔离：使用单独的cache集群或MySQL数据库来提供热点数据
2、动静分离（静态数据可以缓存在CDN）
3、防止无效请求进入服务器（如：1、库存100，进来1000个请求，就有900个无效请求；2、同一个IP请求频率太高）
4、限流（gateway可以实现：IP限流、用户ID限流、接口URI限流）
5、防止页面重复提交（使用分布式锁）
6、流量削峰（MQ可以实现，但是也会达到上限；秒杀答题，最早的使用方法，防止秒杀器，延缓请求）
7、做好熔断降级、线程隔离，防止雪崩
8、利用缓存应对读请求，利用缓存减轻数据库压力
9、利用缓存应对写请求，所有减库存操作都在redis里面进行，等到秒杀结束后再使用mq或多线程同步到数据库
10、分层过滤

4、高并发解决方案
|-防火墙，防病毒和其他攻击
|-负载均衡器
  |--对请求做初步分析，决定是否分发请求到WEB，比如：作弊的IP封禁
  |--路由转发，减轻单台服务器的压力
  |--限流，比如：某时刻请求量太大，可以告知用户系统繁忙，稍后再试
|-无效请求
  |--一个账号发起大量请求，是的后台压力变大，可以加验证码（当然，第一次不需要验证码，第二次开始需要）和限制单位时间内一个账号的请求数量
  |--一个人多个账号场景，可以使用实名认证来解决
  |--真正的多账号，可以使用僵尸账号（平时没有任何交易的账号，只是在特殊的日子交易，比如春运）排除法
|-动静分离：静态数据可以缓存在CDN节点上
|-超卖现象解决
  |--悲观锁：属于数据库锁机制，性能差【for update】
  |--乐观锁：失败率高，但可以使用重入机制解决，但性能还是不够好【UPDATE employee SET money = 100, version = 90 + 1 WHERE id = 111 AND 90 = version】
  |--redis：使用LUA语言保证原子性和数据的一致性，然后再加上MQ异步的将数据分段的持久化到数据库
|-使用springcloud全家桶
  |--服务降级：在高并发情况下，为了防止用户一直等待，直接给用户返回一个友好的提示
  |--服务熔断：熔断机制是为了保护服务，在高并发情况下，如果流量超出设定的阈值，直接拒绝访问服务接口，然后和服务降级一起使用的
     |---如果当前健康状况（请求失败数/请求总数）高于设定阈值（默认为10秒内的20次故障），开关保持关闭，反之，开关打开，请求被禁止通过，进入降级操作，
         经过一段时间后，断路器会进入半开状态，这是只允许一个请求通过，如果该请求成功，则断路器保持关闭状态，反之，打开状态
  |--雪崩效应：由于默认情况下，只有一个线程池维护所有的服务接口，如果流量达到tomcat线程池默认的极限，可能导致服务无法访问
  |--服务隔离：保证每个服务接口互不影响。用来解决雪崩的，有两种方式【线程池、信号量】
  |--雪崩效应解决：
     |---通过Hystrix的服务降级【为了用户体验，fallback使用异步线程callable和future返回结果】
     |---服务熔断机制【为了保护服务，如果流量超出设置的默认的阈值10，自动开启保护服务功能，和降级一起使用】
     |---服务隔离【线程池隔离：使用@HystrixCommand会另外开启一个线程池】，注意走降级超时时间，默认是1秒

5、Mysql与Redis一致性
|-使用阿里的Canal同步框架





















